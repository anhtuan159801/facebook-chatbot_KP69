"""
SCRAPER TH·ª¶ T·ª§C H√ÄNH CH√çNH - T·∫§T C·∫¢ B·ªò/NG√ÄNH
=======================================================
‚úÖ Ch·ªçn ƒë∆∞·ª£c b·∫•t k·ª≥ B·ªô/Ng√†nh n√†o
‚úÖ T·∫£i file h∆∞·ªõng d·∫´n (.doc)
‚úÖ M·ªói th·ªß t·ª•c m·ªôt folder ri√™ng
‚úÖ Ghi r√µ t√™n th·ªß t·ª•c trong danh s√°ch
‚úÖ Th√™m link th·ªß t·ª•c v√†o cu·ªëi file Word
‚úÖ Auto convert .doc ‚Üí .docx

C√ÄI ƒê·∫∂T:
  pip install selenium requests python-docx

  Windows: pip install pywin32
  Linux/Mac: sudo apt-get install libreoffice (ho·∫∑c brew install libreoffice)
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import Select
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import os
import re
import json
from urllib.parse import urljoin
from docx import Document
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
import subprocess
import platform
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import hashlib

# Danh s√°ch c√°c B·ªô/Ng√†nh
MINISTRIES = {
    "1": "B·ªô C√¥ng an",
    "2": "B·ªô C√¥ng th∆∞∆°ng",
    "3": "B·ªô D√¢n t·ªôc v√† T√¥n gi√°o",
    "4": "B·ªô Gi√°o d·ª•c v√† ƒê√†o t·∫°o",
    "5": "B·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá",
    "6": "B·ªô Ngo·∫°i giao",
    "7": "B·ªô N·ªôi v·ª•",
    "8": "B·ªô N√¥ng nghi·ªáp v√† M√¥i tr∆∞·ªùng",
    "9": "B·ªô Qu·ªëc ph√≤ng",
    "10": "B·ªô T√†i ch√≠nh",
    "11": "B·ªô T∆∞ ph√°p",
    "12": "B·ªô VƒÉn h√≥a, Th·ªÉ thao v√† Du l·ªãch",
    "13": "B·ªô Y t·∫ø",
    "14": "Ng√¢n h√†ng Ch√≠nh s√°ch x√£ h·ªôi",
    "15": "Ng√¢n h√†ng Nh√† n∆∞·ªõc Vi·ªát Nam",
    "16": "Ng√¢n h√†ng ph√°t tri·ªÉn Vi·ªát Nam",
    "17": "Thanh tra Ch√≠nh ph·ªß",
    "18": "T√≤a √°n nh√¢n d√¢n",
    "19": "T·∫≠p ƒëo√†n ƒêi·ªán l·ª±c Vi·ªát Nam",
    "20": "VƒÉn ph√≤ng Ch√≠nh ph·ªß"
}

class ProcedureScraper:
    """Class ch√≠nh ƒë·ªÉ scrape th·ªß t·ª•c h√†nh ch√≠nh"""

    def __init__(self, download_dir='downloads', max_workers=8, headless=True):
        self.download_dir = os.path.abspath(download_dir)
        os.makedirs(self.download_dir, exist_ok=True)

        self.max_workers = max_workers
        self.headless = headless
        self.stats = {'success': 0, 'failed': 0, 'cached': 0}
        self.stats_lock = threading.Lock()

        # Cache
        self.cache_file = 'cache_ministries.json'
        self.cache = self._load_cache()
        self.cache_lock = threading.Lock()

        # Main driver cho vi·ªác browse danh s√°ch
        self.driver = self._create_driver()
        self.wait = WebDriverWait(self.driver, 15)

        # Session requests
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

        print(f"OK Khoi tao thanh cong")
        print(f"Folder: {self.download_dir}")
        print(f"Headless mode: {headless}")
        print(f"Max workers: {max_workers}\n")

    def _create_driver(self):
        """T·∫°o m·ªôt Chrome driver m·ªõi"""
        chrome_options = Options()
        if self.headless:
            chrome_options.add_argument('--headless=new')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        # Add performance optimizations
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-images')  # Don't load images to save bandwidth and speed up
        chrome_options.add_argument('--blink-settings=imagesEnabled=false')  # Alternative to disable images

        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(20)
        # Set script timeout
        driver.set_script_timeout(15)
        # Implicit wait for elements
        driver.implicitly_wait(5)
        return driver

    def _load_cache(self):
        """Load cache t·ª´ file"""
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except json.JSONDecodeError as e:
                print(f"Warning - L·ªói ƒë·ªçc file cache '{self.cache_file}': {e}. T·∫°o cache m·ªõi.")
                return {}
            except Exception as e:
                print(f"Warning - L·ªói kh√¥ng x√°c ƒë·ªãnh khi t·∫£i cache '{self.cache_file}': {e}. T·∫°o cache m·ªõi.")
                return {}
        return {}

    def _save_cache(self):
        """L∆∞u cache ra file"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Warning - Kh√¥ng th·ªÉ l∆∞u cache: {e}")

    def setup_advanced_search(self, ministry_name):
        """
        Setup t√¨m ki·∫øm n√¢ng cao cho B·ªô/Ng√†nh c·ª• th·ªÉ
        """
        try:
            # B∆Ø·ªöC 1: Click "T√¨m ki·∫øm n√¢ng cao"
            print(f"üîç B∆∞·ªõc 1: Click 'T√¨m ki·∫øm n√¢ng cao'...", end=" ")
            # B∆Ø·ªöC 1: Click "T√¨m ki·∫øm n√¢ng cao"
            print(f"üîç B∆∞·ªõc 1: Click 'T√¨m ki·∫øm n√¢ng cao'...", end=" ")
            try:
                adv_search = self.wait.until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, "div.adv"))
                )
                adv_search.click()
                # Wait for the select2 dropdown to become visible after clicking advanced search
                self.wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "span.select2-selection__rendered[id='select2-select-implementation-agency-container']")))
                print("‚úÖ")
            except TimeoutException:
                print("‚ö†Ô∏è (C√≥ th·ªÉ ƒë√£ m·ªü s·∫µn ho·∫∑c selector ƒë√£ thay ƒë·ªïi)")
            except Exception as e:
                print(f"‚ùå L·ªói khi click t√¨m ki·∫øm n√¢ng cao: {e}")
                return False

            # B∆Ø·ªöC 2: Ch·ªçn B·ªô/Ng√†nh t·ª´ dropdown Select2
            print(f"üè¢ B∆∞·ªõc 2: Ch·ªçn '{ministry_name}'...", end=" ")

            # Click v√†o dropdown Select2
            select2_container = self.wait.until(
                EC.element_to_be_clickable((
                    By.CSS_SELECTOR,
                    "span.select2-selection__rendered[id='select2-select-implementation-agency-container']"
                ))
            )
            select2_container.click()

            # Wait for search box or options to appear
            try:
                # Try to find and click the option directly
                option = self.wait.until(
                    EC.element_to_be_clickable((
                        By.XPATH,
                        f"//li[contains(@class, 'select2-results__option') and contains(text(), '{ministry_name}')]"
                    ))
                )
                option.click()
                print("‚úÖ")
            except TimeoutException:
                # Fallback: Use search box if direct click fails
                try:
                    search_box = self.wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "input.select2-search__field")))
                    search_box.send_keys(ministry_name)
                    option = self.wait.until(
                        EC.element_to_be_clickable((
                            By.XPATH,
                            "//li[contains(@class, 'select2-results__option')]"
                        ))
                    )
                    option.click()
                    print("‚úÖ")
                except Exception as e:
                    print(f"‚ùå Kh√¥ng ch·ªçn ƒë∆∞·ª£c: {e}")
                    return False

            # Wait for the select2 dropdown to close or become invisible
            self.wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, "input.select2-search__field")))

            # B∆Ø·ªöC 3: Click n√∫t "T√¨m ki·∫øm"
            print("üîé B∆∞·ªõc 3: Click n√∫t 'T√¨m ki·∫øm'...", end=" ")
            search_btn = self.wait.until(
                EC.element_to_be_clickable((By.ID, "btn-search"))
            )
            search_btn.click()
            # Wait for the search results table to be present and contain data (or a loading indicator to disappear)
            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr td a[href*='ma_thu_tuc=']")))
            print("‚úÖ")

            # B∆Ø·ªöC 4: Ch·ªçn 50 h√†ng/trang
            print("üìä B∆∞·ªõc 4: Ch·ªçn 50 h√†ng/trang...", end=" ")
            select_el = self.wait.until(
                EC.presence_of_element_located((By.ID, "paginationRecsPerPage"))
            )
            Select(select_el).select_by_value("50")
            # Wait for the table content to refresh after changing items per page
            # This is a generic wait, a more specific one could be to wait for the number of rows to change
            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr td a[href*='ma_thu_tuc=']")))
            print("‚úÖ")

            print("‚úÖ Setup ho√†n t·∫•t!\n")
            return True

        except Exception as e:
            print(f"\n‚ùå L·ªói setup: {e}")
            import traceback
            traceback.print_exc()
            return False

    def get_current_page_number(self):
        """L·∫•y s·ªë trang hi·ªán t·∫°i"""
        try:
            active = self.driver.find_element(By.CSS_SELECTOR, "li.active[jp-role='page']")
            return int(active.get_attribute('jp-data'))
        except NoSuchElementException:
            return 1 # Assume page 1 if active page element not found
        except ValueError:
            print(f"   ‚ö†Ô∏è Could not parse current page number, defaulting to 1.")
            return 1
        except Exception as e:
            print(f"   ‚ùå Error getting current page number: {e}, defaulting to 1.")
            return 1

    def get_total_pages(self):
        """L·∫•y t·ªïng s·ªë trang"""
        try:
            last_btn = self.driver.find_element(By.CSS_SELECTOR, "li.last[jp-role='last']")
            total = int(last_btn.get_attribute('jp-data'))
            return total
        except NoSuchElementException:
            try:
                page_nums = self.driver.find_elements(By.CSS_SELECTOR, "li[jp-role='page']")
                if page_nums:
                    return max([int(p.get_attribute('jp-data')) for p in page_nums])
            except (NoSuchElementException, ValueError) as e:
                print(f"   ‚ö†Ô∏è Could not determine total pages from page numbers: {e}, defaulting to 1.")
            return 1 # Default to 1 if last page button or page numbers are not found
        except ValueError:
            print(f"   ‚ö†Ô∏è Could not parse total pages number, defaulting to 1.")
            return 1
        except Exception as e:
            print(f"   ‚ùå Error getting total pages: {e}, defaulting to 1.")
            return 1

    def go_to_next_page(self):
        """Chuy·ªÉn sang trang ti·∫øp theo"""
        try:
            current_page = self.get_current_page_number()
            print(f"   üìÑ ƒêang ·ªü trang {current_page}, chuy·ªÉn sang trang {current_page + 1}...", end=" ")

            next_btn = self.wait.until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "li.next:not(.disabled) a"))
            )
            next_btn.click()

            # ƒê·ª£i cho ƒë·∫øn khi s·ªë trang thay ƒë·ªïi
            try:
                self.wait.until(EC.text_to_be_present_in_element_attribute(
                    (By.CSS_SELECTOR, "li.active[jp-role='page']"), 'jp-data', str(current_page + 1)
                ))
                print(f"‚úÖ ƒê√£ chuy·ªÉn sang trang {current_page + 1}")
                # Optional: Add a small sleep if the page content takes a moment to fully render after the page number updates
                # time.sleep(1)
                return True
            except TimeoutException:
                print(f"‚ö†Ô∏è Timeout khi chuy·ªÉn trang")
                return False

        except Exception as e:
            print(f"‚ùå L·ªói: {e}")
            return False

    def extract_procedures_from_page(self):
        """L·∫•y danh s√°ch th·ªß t·ª•c t·ª´ trang hi·ªán t·∫°i"""
        procedures = []
        seen_ids = set()

        try:
            # Wait for at least one procedure link to be present
            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr td a[href*='ma_thu_tuc=']")))

            links = self.driver.find_elements(
                By.CSS_SELECTOR,
                "table tbody tr td a[href*='ma_thu_tuc=']"
            )

            print(f"   üîç T√¨m th·∫•y {len(links)} links")

            for link in links:
                try:
                    href = link.get_attribute('href')
                    if not href:
                        print(f"   ‚ö†Ô∏è Link tr·ªëng, b·ªè qua.")
                        continue

                    match = re.search(r'ma_thu_tuc=(\d+)', href)
                    if not match:
                        print(f"   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ma_thu_tuc trong link: {href}, b·ªè qua.")
                        continue

                    proc_id = match.group(1)

                    if proc_id in seen_ids:
                        print(f"   ‚ö†Ô∏è Th·ªß t·ª•c tr√πng l·∫∑p ID: {proc_id}, b·ªè qua.")
                        continue
                    seen_ids.add(proc_id)

                    # L·∫•y m√£ hi·ªÉn th·ªã
                    code = f"TTHC-{proc_id}" # Default value
                    try:
                        code_span = link.find_element(By.CSS_SELECTOR, "span.link.thick")
                        code = code_span.text.strip()
                    except NoSuchElementException:
                        pass # Use default code if thick span not found

                    # L·∫•y t√™n th·ªß t·ª•c (to√†n b·ªô text tr·ª´ m√£)
                    full_text = link.text.strip()
                    title = full_text.replace(code, '').strip()
                    if not title:
                        title = f"Th·ªß t·ª•c {proc_id}"
                        print(f"   ‚ö†Ô∏è T√™n th·ªß t·ª•c tr·ªëng, d√πng m·∫∑c ƒë·ªãnh: {title}")


                    procedures.append({
                        'id': proc_id,
                        'code': code,
                        'title': title,
                        'url': href
                    })

                except Exception as link_e:
                    print(f"   ‚ùå L·ªói khi x·ª≠ l√Ω link th·ªß t·ª•c: {link_e}")
                    continue

        except TimeoutException:
            print(f"   ‚ö†Ô∏è Timeout khi ƒë·ª£i b·∫£ng th·ªß t·ª•c. C√≥ th·ªÉ kh√¥ng c√≥ th·ªß t·ª•c n√†o tr√™n trang n√†y.")
        except Exception as e:
            print(f"   ‚ö†Ô∏è L·ªói chung khi extract th·ªß t·ª•c: {e}")

        return procedures

        return procedures

    def get_all_procedures(self, url, ministry_name):
        """L·∫•y t·∫•t c·∫£ th·ªß t·ª•c c·ªßa m·ªôt B·ªô/Ng√†nh"""
        print("="*70)
        print(f"üöÄ B·∫ÆT ƒê·∫¶U L·∫§Y DANH S√ÅCH TH·ª¶ T·ª§C - {ministry_name.upper()}")
        print("="*70)

        self.driver.get(url)
        self.wait.until(EC.presence_of_element_located((By.ID, "btn-search"))) # Wait for a key element to indicate page load

        if not self.setup_advanced_search(ministry_name):
            print("‚ùå Kh√¥ng th·ªÉ setup t√¨m ki·∫øm!")
            return []

        all_procedures = []
        total_pages = self.get_total_pages()
        current = self.get_current_page_number()

        print(f"üìä T·ªïng s·ªë trang: {total_pages}")
        print(f"üìä Trang hi·ªán t·∫°i: {current}\n")

        for page_num in range(1, total_pages + 1):
            current_page = self.get_current_page_number()
            print(f"üìÑ Trang {current_page}/{total_pages}")

            procs = self.extract_procedures_from_page()

            if not procs:
                print("   ‚ö†Ô∏è Kh√¥ng l·∫•y ƒë∆∞·ª£c th·ªß t·ª•c n√†o!")
                break

            all_procedures.extend(procs)
            print(f"   ‚úÖ L·∫•y ƒë∆∞·ª£c {len(procs)} th·ªß t·ª•c | T·ªïng: {len(all_procedures)}\n")

            if page_num < total_pages:
                if not self.go_to_next_page():
                    print("   ‚ö†Ô∏è D·ª´ng l·∫°i v√¨ kh√¥ng th·ªÉ chuy·ªÉn trang\n")
                    break

        # Lo·∫°i b·ªè duplicate
        unique_dict = {}
        for p in all_procedures:
            if p['id'] not in unique_dict:
                unique_dict[p['id']] = p

        unique_procs = list(unique_dict.values())

        print(f"‚úÖ T·ªîNG C·ªòNG: {len(unique_procs)} th·ªß t·ª•c duy nh·∫•t")
        if len(all_procedures) > len(unique_procs):
            print(f"   (ƒê√£ lo·∫°i b·ªè {len(all_procedures) - len(unique_procs)} duplicate)\n")

        return unique_procs

    def download_procedure_guide(self, procedure, ministry_folder):
        """
        T·∫£i file h∆∞·ªõng d·∫´n (.doc) c·ªßa m·ªôt th·ªß t·ª•c
        """
        proc_id = procedure['id']
        proc_code = procedure['code']
        proc_title = procedure['title']

        # T·∫°o folder cho B·ªô/Ng√†nh
        safe_code = re.sub(r'[^\w\-]', '_', proc_code)
        huong_dan_folder = os.path.join(ministry_folder, "huong_dan")
        os.makedirs(huong_dan_folder, exist_ok=True)

        # This function is not called in the main `run` loop, `download_procedure_parallel` is.
        # However, for consistency and robustness, we will update its cache logic to match
        # `download_procedure_parallel`. If this function were to be used, it would need its
        # own driver instance if used in parallel. For now, we assume it's used sequentially
        # and thus `self.driver` is acceptable.

        cache_key = f"{ministry_folder}_{proc_id}"
        cached_entry = self.cache.get(cache_key, {})

        doc_filename = f"{safe_code}.doc"
        docx_filename = f"{safe_code}.docx"
        doc_path = os.path.join(huong_dan_folder, doc_filename)
        docx_path = os.path.join(huong_dan_folder, docx_filename)

        final_filepath = None
        needs_download = True

        # Check if docx exists and is valid
        if os.path.exists(docx_path):
            current_size = os.path.getsize(docx_path)
            if current_size > 0 and (cached_entry.get('size') is None or current_size == cached_entry.get('size')):
                if cached_entry.get('checksum'):
                    current_checksum = self._calculate_file_checksum(docx_path)
                    if current_checksum and current_checksum == cached_entry.get('checksum'):
                        final_filepath = docx_path
                        needs_download = False
                        self.stats['cached'] += 1 # No lock needed as this is not parallel
                        print(f"   File already exists and validated: {proc_code}.docx (cached)")
                    else:
                        os.remove(docx_path)
                        print(f"   Checksum mismatch for {proc_code}.docx, re-downloading.")
                else:
                    final_filepath = docx_path
                    needs_download = False
                    self.stats['cached'] += 1 # No lock needed as this is not parallel
                    print(f"   File already exists: {proc_code}.docx (cached, no checksum validation)")
            else:
                if os.path.exists(docx_path): os.remove(docx_path)
                print(f"   File size mismatch for {proc_code}.docx, re-downloading.")

        # If docx doesn't exist or is invalid, check doc
        elif os.path.exists(doc_path):
            current_size = os.path.getsize(doc_path)
            if current_size > 0 and (cached_entry.get('size') is None or current_size == cached_entry.get('size')):
                if cached_entry.get('checksum'):
                    current_checksum = self._calculate_file_checksum(doc_path)
                    if current_checksum and current_checksum == cached_entry.get('checksum'):
                        final_filepath = doc_path
                        needs_download = False
                        self.stats['cached'] += 1 # No lock needed as this is not parallel
                        print(f"   File already exists and validated: {proc_code}.doc (cached)")
                    else:
                        os.remove(doc_path)
                        print(f"   Checksum mismatch for {proc_code}.doc, re-downloading.")
                else:
                    final_filepath = doc_path
                    needs_download = False
                    self.stats['cached'] += 1 # No lock needed as this is not parallel
                    print(f"   File already exists: {proc_code}.doc (cached, no checksum validation)")
            else:
                if os.path.exists(doc_path): os.remove(doc_path)
                print(f"   File size mismatch for {proc_code}.doc, re-downloading.")

        if not needs_download: # Only process if not downloading a fresh copy
            current_filepath = final_filepath
            if current_filepath.endswith('.doc'):
                print(f"   Converting cached .doc to .docx for {proc_code}...")
                current_filepath = self._convert_doc_to_docx(current_filepath)
                final_filepath = current_filepath # Update final_filepath after conversion

            if final_filepath and final_filepath.endswith('.docx'):
                print(f"   Adding link to cached .docx for {proc_code}...")
                final_processed_filepath = self._add_link_to_word_file(final_filepath, procedure['url'])

                if final_processed_filepath:
                    # Update checksum/size in cache after potential conversion/link addition
                    self.cache[cache_key]['checksum'] = self._calculate_file_checksum(final_processed_filepath)
                    self.cache[cache_key]['size'] = os.path.getsize(final_processed_filepath)
                else:
                    print(f"   Warning: Could not add link to cached file {proc_code}.docx.")
            else:
                print(f"   Warning: Cached file {proc_code} not .docx after conversion attempt, skipping link add.")
            return True # File was handled, either downloaded or processed from cache

        # Proceed with download if needs_download is True
        try:
            # Delay ng·∫´u nhi√™n ƒë·ªÉ tr√°nh spam
            time.sleep(0.5 + (hash(proc_id) % 10) * 0.1)

            # M·ªü trang chi ti·∫øt
            self.driver.get(procedure['url'])
            # Use WebDriverWait here instead of hardcoded time.sleep
            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            self.wait.until(EC.visibility_of_element_located((By.XPATH, "//a[.//i[contains(@class, 'fa-file-word')]]")))


            # T·∫£i file h∆∞·ªõng d·∫´n ch√≠nh (.doc)
            download_url = None
            try:
                word_link = self.driver.find_element(By.XPATH,
                    "//a[.//i[contains(@class, 'fa-file-word')]]"
                )
                download_url = word_link.get_attribute('href')
            except NoSuchElementException:
                print(f"   ‚ö†Ô∏è [{proc_code}] Kh√¥ng t√¨m th·∫•y link h∆∞·ªõng d·∫´n")

            if download_url:
                filename = f"{safe_code}.doc"
                filepath = os.path.join(huong_dan_folder, filename)

                if self._download_file(download_url, filepath):
                    # Convert and add link, then update cache with the final filepath
                    final_processed_filepath = self._add_link_to_word_file(filepath, procedure['url'])
                    if final_processed_filepath:
                        # Calculate checksum for the downloaded file
                        checksum = self._calculate_file_checksum(final_processed_filepath)
                        file_size = os.path.getsize(final_processed_filepath)
                        # C·∫≠p nh·∫≠t cache
                        self.cache[cache_key] = {
                            'code': proc_code,
                            'title': proc_title,
                            'downloaded': True,
                            'checksum': checksum,
                            'size': file_size
                        }
                        self.stats['success'] += 1
                        print(f"   ‚úÖ [{proc_code}] ƒê√£ t·∫£i file h∆∞·ªõng d·∫´n v√† x·ª≠ l√Ω")
                        return True
                    else:
                        print(f"   ‚ö†Ô∏è [{proc_code}] ƒê√£ t·∫£i file nh∆∞ng kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi/th√™m link.")
                        self.stats['failed'] += 1 # Count as failed if post-processing fails
                        return False


            print(f"   ‚ö†Ô∏è [{proc_code}] Kh√¥ng t·∫£i ƒë∆∞·ª£c file h∆∞·ªõng d·∫´n")
            self.stats['failed'] += 1
            return False

        except Exception as e:
            print(f"   ‚ùå [{proc_code}] L·ªói: {str(e)[:80]}")
            self.stats['failed'] += 1
            return False

            print(f"   ‚ö†Ô∏è [{proc_code}] Kh√¥ng t·∫£i ƒë∆∞·ª£c file h∆∞·ªõng d·∫´n")
            self.stats['failed'] += 1
            return False

        except Exception as e:
            print(f"   ‚ùå [{proc_code}] L·ªói: {str(e)[:80]}")
            self.stats['failed'] += 1
            return False

    def _convert_doc_to_docx(self, doc_path):
        """
        Convert file .doc sang .docx
        H·ªó tr·ª£ 3 ph∆∞∆°ng ph√°p:
        1. Windows: D√πng win32com (MS Word)
        2. Linux/Mac: D√πng LibreOffice
        3. Fallback: ƒê·ªïi t√™n (kh√¥ng convert th·∫≠t)
        """
        docx_path = doc_path.replace('.doc', '.docx')

        # N·∫øu ƒë√£ l√† .docx, return lu√¥n
        if doc_path.endswith('.docx'):
            return doc_path

        try:
            system = platform.system()

            # PH∆Ø∆†NG PH√ÅP 1: Windows - D√πng MS Word COM
            if system == 'Windows':
                try:
                    import win32com.client
                    import pythoncom

                    # Initialize COM for this thread if not already initialized
                    # This check helps avoid re-initialization errors
                    try:
                        pythoncom.CoInitialize()
                    except pythoncom.com_error as com_err:
                        # HRESULT = -2147417850 means already initialized
                        if com_err.args[0] != -2147417850:
                            raise

                    word = win32com.client.Dispatch('Word.Application')
                    word.Visible = False

                    # M·ªü file .doc
                    doc = word.Documents.Open(os.path.abspath(doc_path))

                    # L∆∞u th√†nh .docx (format 16 = docx)
                    doc.SaveAs2(os.path.abspath(docx_path), FileFormat=16)
                    doc.Close()
                    word.Quit()

                    # X√≥a file .doc c≈©
                    if os.path.exists(docx_path):
                        os.remove(doc_path)
                        return docx_path

                except ImportError:
                    print("   ‚ö†Ô∏è C√†i pywin32 ƒë·ªÉ convert: pip install pywin32")
                except Exception as e:
                    print(f"   ‚ùå L·ªói khi convert .doc b·∫±ng win32com: {e}")
                finally:
                    # Uninitialize COM for this thread
                    try:
                        pythoncom.CoUninitialize()
                    except:
                        pass # Ignore errors during uninitialize

            # PH∆Ø∆†NG PH√ÅP 2: Linux/Mac - D√πng LibreOffice
            elif system in ['Linux', 'Darwin']:
                try:
                    # T√¨m LibreOffice
                    libreoffice_cmd = None
                    for cmd in ['libreoffice', 'soffice', '/usr/bin/libreoffice',
                                '/Applications/LibreOffice.app/Contents/MacOS/soffice']:
                        # Check if command exists and is executable
                        if subprocess.run(['which', cmd], capture_output=True, shell=True).returncode == 0 or os.path.exists(cmd):
                            libreoffice_cmd = cmd
                            break

                    if libreoffice_cmd:
                        # Convert b·∫±ng LibreOffice
                        output_dir = os.path.dirname(doc_path)
                        subprocess.run([
                            libreoffice_cmd,
                            '--headless',
                            '--convert-to', 'docx',
                            '--outdir', output_dir,
                            doc_path
                        ], check=True, capture_output=True, timeout=60) # Increased timeout for LibreOffice

                        # X√≥a file .doc c≈©
                        if os.path.exists(docx_path):
                            os.remove(doc_path)
                            return docx_path
                    else:
                        print("   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y LibreOffice. C√†i ƒë·∫∑t: sudo apt-get install libreoffice (Linux) ho·∫∑c brew install libreoffice (Mac)")

                except subprocess.CalledProcessError as e:
                    print(f"   ‚ùå L·ªói khi ch·∫°y LibreOffice ƒë·ªÉ convert: {e.stderr.decode()}")
                except subprocess.TimeoutExpired:
                    print(f"   ‚ùå LibreOffice timeout khi convert '{doc_path}'.")
                except Exception as e:
                    print(f"   ‚ùå L·ªói khi convert .doc b·∫±ng LibreOffice: {e}")

            # PH∆Ø∆†NG PH√ÅP 3: Fallback - ƒê·ªïi t√™n (kh√¥ng convert th·∫≠t)
            if os.path.exists(doc_path):
                print(f"   ‚ö†Ô∏è Fallback: Kh√¥ng th·ªÉ convert .doc sang .docx th·∫≠t, ƒë·ªïi t√™n '{doc_path}' th√†nh '{docx_path}' (kh√¥ng convert n·ªôi dung).")
                os.rename(doc_path, docx_path)
                return docx_path

        except Exception as e:
            print(f"   ‚ùå L·ªói chung khi convert .doc sang .docx: {e}")

        # N·∫øu t·∫•t c·∫£ ƒë·ªÅu th·∫•t b·∫°i, return file g·ªëc
        return doc_path

    def _calculate_file_checksum(self, filepath):
        """Calculate MD5 checksum of a file"""
        hash_md5 = hashlib.md5()
        try:
            with open(filepath, "rb") as f:
                # Read file in chunks to handle large files efficiently
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except FileNotFoundError:
            print(f"   ‚ö†Ô∏è File not found for checksum calculation: {filepath}")
            return None
        except IOError as e:
            print(f"   ‚ùå Error reading file for checksum calculation {filepath}: {e}")
            return None
        except Exception as e:
            print(f"   ‚ùå Unexpected error during checksum calculation {filepath}: {e}")
            return None

    def _add_link_to_word_file(self, filepath, url):
        """Th√™m link th·ªß t·ª•c v√†o cu·ªëi file Word"""
        try:
            # Convert .doc sang .docx n·∫øu c·∫ßn
            if filepath.endswith('.doc'):
                filepath = self._convert_doc_to_docx(filepath)

            # N·∫øu v·∫´n l√† .doc (convert th·∫•t b·∫°i), b·ªè qua
            if not filepath.endswith('.docx'):
                print(f"   ‚ö†Ô∏è Kh√¥ng th·ªÉ th√™m link v√†o file kh√¥ng ph·∫£i .docx sau khi chuy·ªÉn ƒë·ªïi: {filepath}")
                return False

            # M·ªü file Word
            doc = Document(filepath)

            # Th√™m paragraph m·ªõi ·ªü cu·ªëi
            doc.add_paragraph()  # D√≤ng tr·ªëng

            # Th√™m text v·ªõi link
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.LEFT

            # Text tr∆∞·ªõc link
            run1 = p.add_run("ƒê·ªÉ xem chi ti·∫øt th·ªß t·ª•c h√†nh ch√≠nh v√† t·∫£i c√°c bi·ªÉu m·∫´u c·∫ßn thi·∫øt, vui l√≤ng truy c·∫≠p link sau: ")
            run1.font.size = Pt(12)
            run1.font.name = 'Times New Roman'

            # Link (m√†u xanh, underline)
            run2 = p.add_run(url)
            run2.font.size = Pt(12)
            run2.font.name = 'Times New Roman'
            run2.font.color.rgb = RGBColor(0, 0, 255)  # M√†u xanh
            run2.font.underline = True

            # L∆∞u l·∫°i file
            doc.save(filepath)
            return filepath # Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n file cu·ªëi c√πng sau khi x·ª≠ l√Ω

        except FileNotFoundError:
            print(f"   ‚ùå Kh√¥ng t√¨m th·∫•y file Word ƒë·ªÉ th√™m link: {filepath}")
            return None
        except Exception as e:
            print(f"   ‚ùå L·ªói khi th√™m link v√†o file Word {filepath}: {e}")
            return None

    def _download_file(self, url, filepath, max_retries=5, retry_delay=3):
        """Download file t·ª´ URL v·ªõi retry v√† validation"""
        # Ensure directory exists before downloading
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        for attempt in range(max_retries + 1):
            try:
                if not url.startswith('http'):
                    url = urljoin('https://thutuc.dichvucong.gov.vn', url)

                # Th·ª≠ download v·ªõi timeout v√† headers ph√π h·ª£p h∆°n
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                    'Accept': 'application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document,*/*',
                    'Accept-Language': 'vi,en-US;q=0.9,en;q=0.8',
                    'Referer': 'https://thutuc.dichvucong.gov.vn/',
                    'Connection': 'keep-alive'
                }
                response = self.session.get(url, headers=headers, timeout=45, stream=True, allow_redirects=True)

                # Kiem tra status code
                if response.status_code not in [200, 206]:  # 206 l√† partial content
                    if response.status_code in [502, 503, 504, 505]:  # Server issues, wait longer
                        delay = retry_delay * (attempt + 1)  # Exponential backoff
                    else:
                        delay = retry_delay

                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Download that bai (status {response.status_code}), thu lai sau {delay}s...")
                        time.sleep(delay)
                        continue
                    return False

                # Kiem tra content-type (phai la file, khong phai HTML error page)
                content_type = response.headers.get('content-type', '').lower()
                if 'text/html' in content_type and 'application' not in content_type:
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Nhan HTML thay vi file, thu lai sau {retry_delay}s...")
                        time.sleep(retry_delay)
                        continue
                    return False

                # Download file with proper error handling
                try:
                    # Ensure the directory exists before writing
                    os.makedirs(os.path.dirname(filepath), exist_ok=True)
                    with open(filepath, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                except OSError as e:
                    # Handle file system errors like WinError 2
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Loi file system: {str(e)}, thu lai sau {retry_delay}s...")
                        time.sleep(retry_delay)
                        continue
                    return False

                # Validate file
                if not os.path.exists(filepath):
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: File khong ton tai sau khi download, thu lai...")
                        time.sleep(retry_delay)
                        continue
                    return False

                file_size = os.path.getsize(filepath)

                # File qua nho (< 500 bytes) co the la error
                if file_size < 500:
                    if os.path.exists(filepath):
                        os.remove(filepath)
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: File qua nho ({file_size} bytes), thu lai sau {retry_delay}s...")
                        time.sleep(retry_delay)
                        continue
                    return False

                # Kiem tra xem co phai file that khong (doc vai bytes dau)
                try:
                    with open(filepath, 'rb') as f:
                        header = f.read(8)
                        if len(header) < 4:
                            if os.path.exists(filepath):
                                os.remove(filepath)
                            if attempt < max_retries:
                                print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Header khong hop le, thu lai sau {retry_delay}s...")
                                time.sleep(retry_delay)
                                continue
                            return False
                except OSError as e:
                    if os.path.exists(filepath):
                        os.remove(filepath)
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Loi doc header file: {str(e)}, thu lai sau {retry_delay}s...")
                        time.sleep(retry_delay)
                        continue
                    return False

                # Neu thanh cong, thoat khoi vong lap retry
                print(f"   OK - Tai thanh cong sau {attempt + 1} lan thu")
                return True

            except requests.exceptions.Timeout:
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                    except:
                        pass
                if attempt < max_retries:
                    print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Timeout khi tai file, thu lai sau {retry_delay}s...")
                    time.sleep(retry_delay)
                else:
                    print(f"   Failed - Timeout sau {max_retries + 1} lan thu")
            except requests.exceptions.RequestException as e:
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                    except:
                        pass
                if attempt < max_retries:
                    print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Request loi: {str(e)[:50]}, thu lai sau {retry_delay}s...")
                    time.sleep(retry_delay)
                else:
                    print(f"   Failed - Request that bai sau {max_retries + 1} lan thu: {str(e)[:100]}")
            except OSError as e:
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                    except:
                        pass
                if attempt < max_retries:
                    print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: OS loi (co the la WinError 2): {str(e)[:50]}, thu lai sau {retry_delay}s...")
                    time.sleep(retry_delay)
                else:
                    print(f"   Failed - OS that bai sau {max_retries + 1} lan thu: {str(e)[:100]}")
            except Exception as e:
                # Xoa file loi neu co
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                    except:
                        pass

                if attempt < max_retries:
                    print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Ngoai le khi tai: {str(e)[:50]}, thu lai sau {retry_delay}s...")
                    time.sleep(retry_delay)
                else:
                    print(f"   Failed - That bai sau {max_retries + 1} lan thu: {str(e)[:100]}")

        return False

    def download_procedure_parallel(self, procedure, ministry_folder):
        """Download m·ªôt th·ªß t·ª•c trong ch·∫ø ƒë·ªô song song"""
        proc_id = procedure['id']
        proc_code = procedure['code']
        proc_title = procedure['title']

        # T·∫°o folder cho B·ªô/Ng√†nh
        safe_code = re.sub(r'[^\w\-]', '_', proc_code)
        huong_dan_folder = os.path.join(ministry_folder, "huong_dan")
        os.makedirs(huong_dan_folder, exist_ok=True)

        # Check cache and file existence
        cache_key = f"{ministry_folder}_{proc_id}"
        cached_entry = self.cache.get(cache_key, {})

        doc_filename = f"{safe_code}.doc"
        docx_filename = f"{safe_code}.docx"
        doc_path = os.path.join(huong_dan_folder, doc_filename)
        docx_path = os.path.join(huong_dan_folder, docx_filename)

        final_filepath = None
        needs_download = True

        # Check if docx exists and is valid
        if os.path.exists(docx_path):
            current_size = os.path.getsize(docx_path)
            if current_size > 0 and (cached_entry.get('size') is None or current_size == cached_entry.get('size')):
                if cached_entry.get('checksum'):
                    current_checksum = self._calculate_file_checksum(docx_path)
                    if current_checksum and current_checksum == cached_entry.get('checksum'):
                        final_filepath = docx_path
                        needs_download = False
                        with self.stats_lock:
                            self.stats['cached'] += 1
                        print(f"   File already exists and validated: {proc_code}.docx (cached)")
                    else:
                        os.remove(docx_path)
                        print(f"   Checksum mismatch for {proc_code}.docx, re-downloading.")
                else:
                    final_filepath = docx_path
                    needs_download = False
                    with self.stats_lock:
                        self.stats['cached'] += 1
                    print(f"   File already exists: {proc_code}.docx (cached, no checksum validation)")
            else:
                if os.path.exists(docx_path): os.remove(docx_path)
                print(f"   File size mismatch for {proc_code}.docx, re-downloading.")

        # If docx doesn't exist or is invalid, check doc
        elif os.path.exists(doc_path):
            current_size = os.path.getsize(doc_path)
            if current_size > 0 and (cached_entry.get('size') is None or current_size == cached_entry.get('size')):
                if cached_entry.get('checksum'):
                    current_checksum = self._calculate_file_checksum(doc_path)
                    if current_checksum and current_checksum == cached_entry.get('checksum'):
                        final_filepath = doc_path
                        needs_download = False
                        with self.stats_lock:
                            self.stats['cached'] += 1
                        print(f"   File already exists and validated: {proc_code}.doc (cached)")
                    else:
                        os.remove(doc_path)
                        print(f"   Checksum mismatch for {proc_code}.doc, re-downloading.")
                else:
                    final_filepath = doc_path
                    needs_download = False
                    with self.stats_lock:
                        self.stats['cached'] += 1
                    print(f"   File already exists: {proc_code}.doc (cached, no checksum validation)")
            else:
                if os.path.exists(doc_path): os.remove(doc_path)
                print(f"   File size mismatch for {proc_code}.doc, re-downloading.")

        if needs_download:
            # T·∫°o driver ri√™ng cho lu·ªìng n√†y
            driver = self._create_driver()
            wait = WebDriverWait(driver, 10)
            try:
                # M·ªü trang chi ti·∫øt
                driver.get(procedure['url'])

                # T·∫£i file h∆∞·ªõng d·∫´n ch√≠nh (.doc)
                download_url = None
                for retry in range(3):
                    try:
                        # ƒê·ª£i page load ho√†n to√†n
                        wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))

                        word_link = driver.find_element(By.XPATH,
                            "//a[.//i[contains(@class, 'fa-file-word')]]"
                        )
                        download_url = word_link.get_attribute('href')
                        break
                    except Exception as e:
                        if retry < 2:
                            time.sleep(0.5)
                        else:
                            print(f"   ‚ö†Ô∏è [{proc_code}] Kh√¥ng t√¨m th·∫•y link h∆∞·ªõng d·∫´n")

                if download_url:
                    filename = f"{safe_code}.doc"
                    filepath = os.path.join(huong_dan_folder, filename)

                    # S·ª≠ d·ª•ng session ri√™ng ƒë·ªÉ download
                    session = requests.Session()
                    session.headers.update({
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    })

                    # Download file
                    if self._download_file_with_session(download_url, filepath, session):
                        # Th√™m link v√†o cu·ªëi file Word v√† l·∫•y ƒë∆∞·ªùng d·∫´n cu·ªëi c√πng sau khi chuy·ªÉn ƒë·ªïi
                        final_processed_filepath = self._add_link_to_word_file(filepath, procedure['url'])

                        if final_processed_filepath:
                            # Calculate checksum for the downloaded file
                            checksum = self._calculate_file_checksum(final_processed_filepath)
                            file_size = os.path.getsize(final_processed_filepath)
                            # C·∫≠p nh·∫≠t cache
                            with self.cache_lock:
                                self.cache[cache_key] = {
                                    'code': proc_code,
                                    'title': proc_title,
                                    'downloaded': True,
                                    'checksum': checksum,
                                    'size': file_size
                                }
                            with self.stats_lock:
                                self.stats['success'] += 1
                            driver.quit()
                            return True, proc_code, "success"
                        else:
                            print(f"   ‚ö†Ô∏è [{proc_code}] ƒê√£ t·∫£i file nh∆∞ng kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi/th√™m link.")
                            with self.stats_lock:
                                self.stats['failed'] += 1 # Count as failed if post-processing fails
                            driver.quit()
                            return False, proc_code, "failed_post_process"

                with self.stats_lock:
                    self.stats['failed'] += 1
                driver.quit()
                return False, proc_code, "failed_download"

            except Exception as e:
                with self.stats_lock:
                    self.stats['failed'] += 1
                driver.quit()
                return False, proc_code, f"error: {str(e)[:50]}"
        else:
            # If not downloading (i.e., cached), ensure it's converted to docx and has link
            current_filepath = final_filepath
            if current_filepath.endswith('.doc'):
                print(f"   Converting cached .doc to .docx for {proc_code}...")
                current_filepath = self._convert_doc_to_docx(current_filepath)
                final_filepath = current_filepath # Update final_filepath after conversion

            if final_filepath and final_filepath.endswith('.docx'):
                print(f"   Adding link to cached .docx for {proc_code}...")
                final_processed_filepath = self._add_link_to_word_file(final_filepath, procedure['url'])

                if final_processed_filepath:
                    # Update checksum/size in cache after potential conversion/link addition
                    with self.cache_lock:
                        self.cache[cache_key]['checksum'] = self._calculate_file_checksum(final_processed_filepath)
                        self.cache[cache_key]['size'] = os.path.getsize(final_processed_filepath)
                else:
                    print(f"   Warning: Could not add link to cached file {proc_code}.docx.")
            else:
                print(f"   Warning: Cached file {proc_code} not .docx after conversion attempt, skipping link add.")
            return True, proc_code, "cached" # Still counted as cached

    def _download_file_with_session(self, url, filepath, session, max_retries=5, retry_delay=3):
        """Download file t·ª´ URL v·ªõi session c·ª• th·ªÉ, c√≥ retry khi l·ªói"""
        # Ensure directory exists before downloading
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        for attempt in range(max_retries + 1):
            try:
                if not url.startswith('http'):
                    url = urljoin('https://thutuc.dichvucong.gov.vn', url)

                # Th·ª≠ download v·ªõi timeout v√† headers ph√π h·ª£p h∆°n
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                    'Accept': 'application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document,*/*',
                    'Accept-Language': 'vi,en-US;q=0.9,en;q=0.8',
                    'Referer': 'https://thutuc.dichvucong.gov.vn/',
                    'Connection': 'keep-alive'
                }
                response = session.get(url, headers=headers, timeout=45, stream=True, allow_redirects=True)

                # Kiem tra status code
                if response.status_code not in [200, 206]:  # 206 l√† partial content
                    if response.status_code in [502, 503, 504, 505]:  # Server issues, wait longer
                        delay = retry_delay * (attempt + 1)  # Exponential backoff
                    else:
                        delay = retry_delay

                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Download that bai (status {response.status_code}), thu lai sau {delay}s...")
                        time.sleep(delay)
                        continue
                    return False

                # Kiem tra content-type (phai la file, khong phai HTML error page)
                content_type = response.headers.get('content-type', '').lower()
                if 'text/html' in content_type and 'application' not in content_type:
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Nhan HTML thay vi file, thu lai sau {retry_delay}s...")
                        time.sleep(retry_delay)
                        continue
                    return False

                # Download file with proper error handling
                try:
                    # Ensure the directory exists before writing
                    os.makedirs(os.path.dirname(filepath), exist_ok=True)
                    with open(filepath, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                except OSError as e:
                    # Handle file system errors like WinError 2
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Loi file system: {str(e)}, thu lai sau {retry_delay}s...")
                        time.sleep(retry_delay)
                        continue
                    return False

                # Validate file
                if not os.path.exists(filepath):
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: File khong ton tai sau khi download, thu lai...")
                        time.sleep(retry_delay)
                        continue
                    return False

                file_size = os.path.getsize(filepath)

                # File qua nho (< 500 bytes) co the la error
                if file_size < 500:
                    if os.path.exists(filepath):
                        os.remove(filepath)
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: File qua nho ({file_size} bytes), thu lai sau {retry_delay}s...")
                        time.sleep(retry_delay)
                        continue
                    return False

                # Kiem tra xem co phai file that khong (doc vai bytes dau)
                try:
                    with open(filepath, 'rb') as f:
                        header = f.read(8)
                        if len(header) < 4:
                            if os.path.exists(filepath):
                                os.remove(filepath)
                            if attempt < max_retries:
                                print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Header khong hop le, thu lai sau {retry_delay}s...")
                                time.sleep(retry_delay)
                                continue
                            return False
                except OSError as e:
                    if os.path.exists(filepath):
                        os.remove(filepath)
                    if attempt < max_retries:
                        print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Loi doc header file: {str(e)}, thu lai sau {retry_delay}s...")
                        time.sleep(retry_delay)
                        continue
                    return False

                # Neu thanh cong, thoat khoi vong lap retry
                print(f"   OK - Tai thanh cong sau {attempt + 1} lan thu")
                return True

            except requests.exceptions.Timeout:
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                    except:
                        pass
                if attempt < max_retries:
                    print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Timeout khi tai file, thu lai sau {retry_delay}s...")
                    time.sleep(retry_delay)
                else:
                    print(f"   Failed - Timeout sau {max_retries + 1} lan thu")
            except requests.exceptions.RequestException as e:
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                    except:
                        pass
                if attempt < max_retries:
                    print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Request loi: {str(e)[:50]}, thu lai sau {retry_delay}s...")
                    time.sleep(retry_delay)
                else:
                    print(f"   Failed - Request that bai sau {max_retries + 1} lan thu: {str(e)[:100]}")
            except OSError as e:
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                    except:
                        pass
                if attempt < max_retries:
                    print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: OS loi (co the la WinError 2): {str(e)[:50]}, thu lai sau {retry_delay}s...")
                    time.sleep(retry_delay)
                else:
                    print(f"   Failed - OS that bai sau {max_retries + 1} lan thu: {str(e)[:100]}")
            except Exception as e:
                # Xoa file loi neu co
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                    except:
                        pass

                if attempt < max_retries:
                    print(f"   Warning - Lan {attempt + 1}/{max_retries + 1}: Ngoai le khi tai: {str(e)[:50]}, thu lai sau {retry_delay}s...")
                    time.sleep(retry_delay)
                else:
                    print(f"   Failed - That bai sau {max_retries + 1} lan thu: {str(e)[:100]}")

        return False

    def download_all_guides(self, procedures, ministry_folder):
        """Download t·∫•t c·∫£ file h∆∞·ªõng d·∫´n v·ªõi ƒëa lu·ªìng"""
        print("="*70)
        print("‚ö° B·∫ÆT ƒê·∫¶U DOWNLOAD FILE H∆Ø·ªöNG D·∫™N (ƒêA LU·ªíNG)")
        print("="*70)

        # First pass: download all procedures
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit all tasks
            future_to_procedure = {
                executor.submit(self.download_procedure_parallel, procedure, ministry_folder): procedure
                for procedure in procedures
            }

            # Track progress
            completed = 0
            total = len(procedures)

            for future in as_completed(future_to_procedure):
                completed += 1
                success, proc_code, status = future.result()

                if status == "cached":
                    print(f"\nüìù [{completed}/{total}] [{proc_code}] ƒê√É C√ì TRONG CACHE")
                elif success:
                    print(f"\n‚úÖ [{completed}/{total}] [{proc_code}] T·∫£i th√†nh c√¥ng")
                else:
                    print(f"\n‚ùå [{completed}/{total}] [{proc_code}] T·∫£i th·∫•t b·∫°i ({status})")

                # In th·ªëng k√™ sau m·ªói 5 th·ªß t·ª•c ho·∫∑c cu·ªëi c√πng
                if completed % 5 == 0 or completed == total:
                    print(f"üìä Ti·∫øn ƒë·ªô: {completed}/{total} | "
                          f"‚úÖ {self.stats['success']} | "
                          f"üíæ {self.stats['cached']} | "
                          f"‚ùå {self.stats['failed']}")

        # Summary of first run
        print(f"\nüìä K·∫æT QU·∫¢ SAU L·∫¶N CH·∫†Y ƒê·∫¶U:")
        print(f"   ‚úÖ Th√†nh c√¥ng: {self.stats['success']}")
        print(f"   üíæ ƒê√£ c√≥ (cache): {self.stats['cached']}")
        print(f"   ‚ùå Th·∫•t b·∫°i: {self.stats['failed']}")

        # Note that the actual retry mechanism is already implemented in the download methods
        # Each download attempt includes built-in retry logic
        if self.stats['failed'] > 0:
            print(f"‚ÑπÔ∏è  C√°c l·∫ßn t·∫£i th·∫•t b·∫°i ƒë√£ ƒë∆∞·ª£c t·ª± ƒë·ªông th·ª≠ l·∫°i theo c∆° ch·∫ø retry n·ªôi t·∫°i")

        print(f"\nüéâ HO√ÄN T·∫§T TI·∫æN TR√åNH T·∫¢I XU·ªêNG!")

        self._save_cache()

    def run(self, url, ministry_name, max_procedures=None):
        """Ch·∫°y scraper cho m·ªôt B·ªô/Ng√†nh"""
        start_time = time.time()

        try:
            # T·∫°o folder cho B·ªô/Ng√†nh
            safe_ministry = re.sub(r'[^\w\-]', '_', ministry_name)
            ministry_folder = os.path.join(self.download_dir, safe_ministry)
            os.makedirs(ministry_folder, exist_ok=True)

            # L·∫•y danh s√°ch th·ªß t·ª•c
            procedures = self.get_all_procedures(url, ministry_name)

            if not procedures:
                print("‚ùå Kh√¥ng t√¨m th·∫•y th·ªß t·ª•c n√†o!")
                return

            # Gi·ªõi h·∫°n n·∫øu c·∫ßn
            if max_procedures:
                procedures = procedures[:max_procedures]
                print(f"‚ö†Ô∏è Gi·ªõi h·∫°n: {max_procedures} th·ªß t·ª•c ƒë·∫ßu ti√™n\n")

            # L∆∞u danh s√°ch v·ªõi t√™n th·ªß t·ª•c ƒë·∫ßy ƒë·ªß
            list_file = os.path.join(ministry_folder, f'danh_sach_{safe_ministry}.txt')
            with open(list_file, 'w', encoding='utf-8') as f:
                f.write(f"DANH S√ÅCH TH·ª¶ T·ª§C H√ÄNH CH√çNH - {ministry_name.upper()}\n")
                f.write("="*80 + "\n")
                f.write(f"T·ªïng s·ªë: {len(procedures)} th·ªß t·ª•c\n")
                f.write(f"Ng√†y t·∫°o: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("="*80 + "\n\n")
                for i, p in enumerate(procedures, 1):
                    f.write(f"{i}. [{p['code']}] {p['title']}\n")
                    f.write(f"   URL: {p['url']}\n\n")

            print(f"‚úÖ ƒê√£ l∆∞u danh s√°ch: {list_file}")
            print(f"üìÅ C·∫•u tr√∫c th∆∞ m·ª•c:")
            print(f"   {ministry_folder}/")
            print(f"   ‚îú‚îÄ‚îÄ huong_dan/     (File h∆∞·ªõng d·∫´n .doc/.docx)")
            print(f"   ‚îî‚îÄ‚îÄ danh_sach_{safe_ministry}.txt\n")

            # Download files
            self.download_all_guides(procedures, ministry_folder)

            # K·∫øt qu·∫£
            elapsed = time.time() - start_time

            print("\n" + "="*70)
            print("üìä K·∫æT QU·∫¢ CU·ªêI C√ôNG")
            print("="*70)
            print(f"‚úÖ Th·ªß t·ª•c th√†nh c√¥ng: {self.stats['success']}")
            print(f"üíæ ƒê√£ c√≥ (cache): {self.stats['cached']}")
            print(f"‚ùå Th·∫•t b·∫°i: {self.stats['failed']}")
            print(f"üìÅ Th∆∞ m·ª•c: {ministry_folder}/")
            print(f"‚è±Ô∏è Th·ªùi gian: {elapsed/60:.1f} ph√∫t")

        except Exception as e:
            print(f"\n‚ùå L·ªói nghi√™m tr·ªçng: {e}")
            import traceback
            traceback.print_exc()

        finally:
            try:
                self.driver.quit()
            except:
                pass
            print("\nüéâ HO√ÄN T·∫§T!")


def get_user_input(prompt, default_value=None, valid_options=None):
    """
    Get user input with fallback for environments where input() might not work
    """
    import sys
    import os

    # Check if stdin is a terminal (TTY)
    if not os.isatty(sys.stdin.fileno()):
        print(f"\n‚ö†Ô∏è Kh√¥ng th·ªÉ nh·∫≠n input t·ª´ ng∆∞·ªùi d√πng (kh√¥ng ph·∫£i m√¥i tr∆∞·ªùng terminal). S·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh: {default_value}")
        return default_value

    try:
        choice = input(prompt).strip()
        if not choice and default_value is not None:
            return default_value
        if valid_options and choice not in valid_options:
            print(f"L·ª±a ch·ªçn '{choice}' kh√¥ng h·ª£p l·ªá. S·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh: {default_value}")
            return default_value
        return choice
    except (EOFError, KeyboardInterrupt):
        # Handle case where no input is available (like when running in certain IDEs)
        print(f"\n‚ö†Ô∏è Kh√¥ng th·ªÉ nh·∫≠n input t·ª´ ng∆∞·ªùi d√πng. S·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh: {default_value}")
        return default_value
    except Exception:
        # Fallback for other environments where input() doesn't work
        print(f"\n‚ö†Ô∏è Kh√¥ng th·ªÉ nh·∫≠n input t·ª´ ng∆∞·ªùi d√πng. S·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh: {default_value}")
        return default_value


def main():
    """H√†m main"""
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   SCRAPER TH·ª¶ T·ª§C H√ÄNH CH√çNH - T·∫§T C·∫¢ B·ªò/NG√ÄNH               ‚ïë
‚ïë  ‚úÖ Ch·ªçn ƒë∆∞·ª£c b·∫•t k·ª≥ B·ªô/Ng√†nh n√†o                            ‚ïë
‚ïë  ‚úÖ T·∫£i file h∆∞·ªõng d·∫´n (.doc)                                ‚ïë
‚ïë  ‚úÖ T·ª± ƒë·ªông convert .doc ‚Üí .docx                             ‚ïë
‚ïë  ‚úÖ Th√™m link th·ªß t·ª•c v√†o cu·ªëi file Word                     ‚ïë
‚ïë  ‚úÖ Ghi r√µ t√™n th·ªß t·ª•c ƒë·∫ßy ƒë·ªß                                ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üì¶ C√ÄI ƒê·∫∂T:
   pip install selenium requests python-docx

   Windows: pip install pywin32
   Linux:   sudo apt-get install libreoffice
   Mac:     brew install libreoffice
""")

    print("üìã DANH S√ÅCH B·ªò/NG√ÄNH:")
    print("="*70)
    for key, name in sorted(MINISTRIES.items(), key=lambda x: int(x[0])):
        print(f"{key:>2}. {name}")

    print("\n‚öôÔ∏è CH·ªåN B·ªò/NG√ÄNH:")
    choice = get_user_input("Nh·∫≠p s·ªë (1-20): ", "1", MINISTRIES.keys())
    ministry_name = MINISTRIES.get(choice)

    if not ministry_name:
        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")
        print("‚úÖ S·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh: B·ªô C√¥ng an (1)")
        ministry_name = MINISTRIES.get("1")
        choice = "1"

    print(f"\n‚úÖ ƒê√£ ch·ªçn: {ministry_name}")

    print("\n‚öôÔ∏è CH·ªåN CH·∫æ ƒê·ªò:")
    print("1. TEST - 5 th·ªß t·ª•c (nhanh, ƒë·ªÉ test)")
    print("2. MEDIUM - 20 th·ªß t·ª•c (ki·ªÉm tra)")
    print("3. FULL - T·∫§T C·∫¢ th·ªß t·ª•c (ch·∫°y th·∫≠t)")

    mode = get_user_input("\nCh·ªçn (1-3) [M·∫∑c ƒë·ªãnh: 1]: ", "1", ["1", "2", "3"])
    if not mode:
        mode = "1"

    limits = {"1": 5, "2": 20, "3": None}
    max_procs = limits.get(mode, 5)

    headless = (mode == "3")

    print(f"\nüöÄ B·∫ÆT ƒê·∫¶U...\n")

    url = "https://thutuc.dichvucong.gov.vn/p/home/dvc-tthc-thu-tuc-hanh-chinh.html"

    try:
        scraper = ProcedureScraper(
            download_dir='downloads_ministries',
            max_workers=8,
            headless=headless
        )
        scraper.run(url, ministry_name, max_procs)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    import sys
    import io
    # Set stdout to handle Unicode characters properly
    if sys.stdout.encoding != 'utf-8':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    main()
